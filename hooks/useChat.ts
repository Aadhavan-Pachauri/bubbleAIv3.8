
import { useState, useEffect, useCallback, useMemo, useRef } from 'react';
import { useAuth } from '../contexts/AuthContext';
import { useToast } from './useToast';
import { Project, Message, Chat, WorkspaceMode, ChatWithProjectData } from '../types';
import { 
    getAllChatsForUser, 
    addMessage, 
    updateChat as updateDbChat, 
    getMessages, 
    deleteChat, 
    updateMessagePlan,
    getChatsForProject,
    extractAndSaveMemory
} from '../services/databaseService';
import { localChatService } from '../services/localChatService';
import { generateChatTitle } from '../services/geminiService';
import { runAgent } from '../agents';
import { User } from '@supabase/supabase-js';
import { AgentExecutionResult } from '../agents/types';
import { NEW_CHAT_NAME } from '../constants';

const DUMMY_AUTONOMOUS_PROJECT: Project = {
  id: 'autonomous-project',
  user_id: 'unknown',
  name: 'Autonomous Chat',
  description: 'A personal chat with the AI.',
  status: 'In Progress',
  platform: 'Web App',
  project_type: 'conversation',
  default_model: 'gemini-2.5-flash',
  created_at: new Date().toISOString(),
  updated_at: new Date().toISOString(),
};

interface UseChatProps {
    user: User | null;
    geminiApiKey: string | null;
    workspaceMode: WorkspaceMode;
    adminProject?: Project | null; 
}

const fileToBase64 = (file: File): Promise<string> => {
    return new Promise((resolve, reject) => {
        const reader = new FileReader();
        reader.readAsDataURL(file);
        reader.onload = () => {
            const result = reader.result as string;
            const base64 = result.split(',')[1];
            resolve(base64);
        };
        reader.onerror = error => reject(error);
    });
};

interface Attachment {
    type: string;
    data: string;
    name: string;
}

export const useChat = ({ user, geminiApiKey, workspaceMode, adminProject }: UseChatProps) => {
    const { supabase, profile, isGuest } = useAuth();
    const { addToast } = useToast();

    const [allChats, setAllChats] = useState<ChatWithProjectData[]>([]);
    const [activeChat, setActiveChat] = useState<ChatWithProjectData | null>(null);
    const [messages, setMessages] = useState<Message[]>([]);
    const [isLoading, setIsLoading] = useState(false);
    const [isCreatingChat, setIsCreatingChat] = useState(false);
    
    // Group Chat Logic: Track active users in channel for presence
    const [activeUsersCount, setActiveUsersCount] = useState(1);
    
    const isSendingRef = useRef(false);
    const activeChatIdRef = useRef<string | null>(null);
    const isMountedRef = useRef(true);
    const abortControllerRef = useRef<AbortController | null>(null);
    
    const previousChatIdRef = useRef<string | null>(null);

    useEffect(() => {
        isMountedRef.current = true;
        return () => { isMountedRef.current = false; };
    }, []);

    useEffect(() => {
        const currentId = activeChat?.id || null;
        if (currentId && previousChatIdRef.current && currentId !== previousChatIdRef.current) {
            setMessages([]); 
        }
        previousChatIdRef.current = currentId;
        activeChatIdRef.current = currentId;
    }, [activeChat?.id]); 

    const activeProject = useMemo(() => adminProject ?? activeChat?.projects ?? null, [adminProject, activeChat]);
    
    useEffect(() => {
        if (!supabase || (!user && !isGuest)) return;
        let isCancelled = false;
        const fetchChats = async () => {
            if (allChats.length === 0) setIsLoading(true);
            try {
                let chats: ChatWithProjectData[] = [];
                if (isGuest) {
                    chats = await localChatService.getAllChats();
                } else if (adminProject) {
                    const projectChats = await getChatsForProject(supabase, adminProject.id);
                    chats = projectChats.map(c => ({...c, projects: adminProject }));
                } else if(user) {
                    chats = await getAllChatsForUser(supabase, user.id);
                }
                if (!isCancelled && isMountedRef.current) {
                    setAllChats(chats);
                }
            } catch (error) {
                console.error("Error fetching chats:", error);
            } finally {
                if (!isCancelled && isMountedRef.current) setIsLoading(false);
            }
        };
        fetchChats();
        return () => { isCancelled = true; };
    }, [user, supabase, adminProject, isGuest]);

    useEffect(() => {
        let isCancelled = false;
        let channel: any = null;

        const fetchMessages = async () => {
            if (activeChat) {
                const chatId = activeChat.id;
                if (!isSendingRef.current && isMountedRef.current && messages.length === 0) {
                    setIsLoading(true);
                }
                try {
                    let history: Message[] = [];
                    if (isGuest) {
                        history = await localChatService.getMessages(chatId);
                    } else if (supabase) {
                        history = await getMessages(supabase, chatId);
                    }
                    if (!isCancelled && isMountedRef.current && activeChatIdRef.current === chatId) {
                        setMessages(prev => {
                            const pendingOptimistic = prev.filter(p => p.id.startsWith('temp-'));
                            if (history.length === 0 && pendingOptimistic.length > 0) {
                                return pendingOptimistic;
                            }
                            if (pendingOptimistic.length === 0) return history;
                            const merged = [...history];
                            pendingOptimistic.forEach(opt => {
                                const isSaved = history.some(h => (h.text === opt.text && h.sender === opt.sender) || h.id === opt.id);
                                if (!isSaved) merged.push(opt);
                            });
                            return merged;
                        });
                    }
                } catch (error) { 
                    console.error("Error fetching messages:", error);
                } 
                finally { 
                    if (!isCancelled && isMountedRef.current && activeChatIdRef.current === chatId) setIsLoading(false); 
                }
            } else {
                if (isMountedRef.current) setMessages([]);
            }
        };

        fetchMessages();
        
        if (activeChat && supabase && !isGuest) {
            const channelName = `chat-room:${activeChat.id}`;
            channel = supabase.channel(channelName)
                .on('postgres_changes', { 
                    event: 'INSERT', 
                    schema: 'public', 
                    table: 'messages', 
                    filter: `chat_id=eq.${activeChat.id}` 
                }, (payload) => {
                    if (!isMountedRef.current) return;
                    const newMsg = payload.new as Message;
                    if (activeChatIdRef.current === activeChat.id) {
                        setMessages(prev => {
                            if (prev.some(m => m.id === newMsg.id)) return prev;
                            const filtered = prev.filter(m => {
                                if (!m.id.startsWith('temp-')) return true;
                                return !(m.text === newMsg.text && m.sender === newMsg.sender);
                            });
                            return [...filtered, newMsg];
                        });
                        
                        // AUTO-REPLY LOGIC FOR GROUP CHAT
                        // If I am NOT the sender, check if the message mentions @Bubble
                        // This prevents every client from triggering the AI. Only the person who SENT it (handled in handleSendMessage) triggers it.
                        // Wait... 'handleSendMessage' handles the AI trigger for the sender. 
                        // The 'listener' just receives the message.
                        // So, we actually don't need logic here. 
                        // The logic for "Only reply if mentioned" goes into handleSendMessage.
                    }
                })
                .on('presence', { event: 'sync' }, () => {
                    // Update active user count for group chat logic
                    const state = channel.presenceState();
                    setActiveUsersCount(Object.keys(state).length);
                })
                .subscribe(async (status) => {
                    if (status === 'SUBSCRIBED') {
                        await channel.track({ online_at: new Date().toISOString(), user_id: user?.id });
                    }
                });
        }

        return () => { 
            isCancelled = true;
            if (channel) {
                supabase.removeChannel(channel); 
            }
        };
    }, [activeChat?.id, supabase, isGuest]);

    const handleSelectChat = useCallback((chat: ChatWithProjectData) => {
        setActiveChat(chat);
    }, []);

    const handleUpdateChat = useCallback(async (chatId: string, updates: Partial<Chat>) => {
        try {
            let updatedChat: Chat;
            if (isGuest) {
                updatedChat = await localChatService.updateChat(chatId, updates);
            } else {
                if (!supabase) return;
                updatedChat = await updateDbChat(supabase, chatId, updates);
            }
            setAllChats(prev => prev.map(c => c.id === chatId ? { ...c, ...updatedChat } : c));
            setActiveChat(prev => {
                if (prev?.id === chatId) return { ...prev, ...updatedChat };
                return prev;
            });
        } catch (error) { 
             console.error("Failed to update chat:", error);
        }
    }, [supabase, isGuest]);

    const handleDeleteChat = async (chatId: string) => {
        try {
            if (isGuest) await localChatService.deleteChat(chatId);
            else { if (!supabase) return; await deleteChat(supabase, chatId); }
            setAllChats(prev => prev.filter(c => c.id !== chatId));
            if (activeChat?.id === chatId) setActiveChat(null);
            addToast('Chat deleted.', 'info');
        } catch (error) {
            addToast('Failed to delete chat.', 'error');
        }
    };

    const handleStopGeneration = useCallback(() => {
        if (abortControllerRef.current) {
            abortControllerRef.current.abort();
            abortControllerRef.current = null;
            isSendingRef.current = false;
            setIsLoading(false);
            addToast("Stopped generating.", "info");
        }
    }, [addToast]);
    
    const handleSendMessage = useCallback(async (
        text: string, 
        files: File[] | null = null, 
        chatToUse: ChatWithProjectData | null = activeChat,
        thinkingModeOrOverride: 'instant' | 'fast' | 'think' | 'deep' | string = 'fast',
        onProjectFileUpdate?: (path: string, content: string, isComplete: boolean) => void
    ): Promise<AgentExecutionResult> => {
      
      const isInstantMode = thinkingModeOrOverride === 'instant' || isGuest;
      const effectiveMode = isGuest ? 'instant' : thinkingModeOrOverride;
      const modelOverride = typeof thinkingModeOrOverride === 'string' && !['instant', 'fast', 'think', 'deep'].includes(thinkingModeOrOverride) ? thinkingModeOrOverride : undefined;

      if ((!text.trim() && (!files || files.length === 0)) || (!user && !isGuest) || !chatToUse) return { messages: [] };
      if (!isInstantMode && !geminiApiKey) return { messages: [] };
      
      // === GROUP CHAT LOGIC ===
      // If we are in Co-Creator mode (likely a team project) OR active users > 1, 
      // we check if the user is explicitly addressing the AI.
      // Exception: If it's a DM with the AI (Autonomous), we always reply.
      const isGroupContext = workspaceMode === 'cocreator' && activeUsersCount > 1;
      const isMentioned = text.toLowerCase().includes('@bubble') || text.toLowerCase().includes('@ai');
      
      if (isGroupContext && !isMentioned) {
          // Just save the user message, DO NOT trigger AI generation
          // We still execute the first part (user message saving) but return early before runAgent.
      }

      if (isSendingRef.current) return { messages: [] };
      isSendingRef.current = true;
      setIsLoading(true);

      const abortController = new AbortController();
      abortControllerRef.current = abortController;

      const safetyTimeout = setTimeout(() => {
          if (isSendingRef.current && !abortController.signal.aborted) {
              console.warn("Response timed out.");
              abortController.abort();
              isSendingRef.current = false;
              if (isMountedRef.current) setIsLoading(false);
              addToast("Response timed out. The operation took too long.", "error");
          }
      }, 300000); 

      const tempId = `temp-ai-${Date.now()}`;
      const tempUserMsgId = `temp-user-${Date.now()}`;
      let currentText = '';

      try {
        let processedPrompt = text;
        const attachments: Attachment[] = [];
        const agentFiles: File[] = [];

        if (files && files.length > 0) {
            for (const file of files) {
                const mimeType = file.type;
                const fileName = file.name.toLowerCase();
                if (mimeType.startsWith('image/') || /\.(jpg|jpeg|png|gif|webp|bmp|svg)$/i.test(fileName)) {
                    const b64 = await fileToBase64(file);
                    attachments.push({ type: mimeType || 'image/jpeg', data: b64, name: file.name });
                    agentFiles.push(file); 
                } else {
                    attachments.push({ type: 'application/octet-stream', data: '', name: file.name });
                    agentFiles.push(file); 
                }
            }
        }

        const displayText = text.trim() === '' && files && files.length > 0 ? "" : text;

        const userMessageData: Omit<Message, 'id' | 'created_at'> = {
          project_id: chatToUse.project_id,
          chat_id: chatToUse.id,
          user_id: user ? user.id : 'guest', 
          text: displayText, 
          sender: 'user',
        };

        if (attachments.length > 0) userMessageData.image_base64 = JSON.stringify(attachments);
        
        const optimisticUserMessage: Message = { ...userMessageData, id: tempUserMsgId, created_at: new Date().toISOString() };
        
        // Only show temp AI message if we are going to generate
        const shouldGenerate = !isGroupContext || isMentioned;
        const tempAiMessage: Message | null = shouldGenerate ? { id: tempId, project_id: chatToUse.project_id, chat_id: chatToUse.id, text: '', sender: 'ai' } : null;
        
        activeChatIdRef.current = chatToUse.id;

        if (isMountedRef.current) {
            setMessages(prev => tempAiMessage ? [...prev, optimisticUserMessage, tempAiMessage] : [...prev, optimisticUserMessage]);
        }
        
        try {
            if (isGuest) await localChatService.addMessage(userMessageData);
            else if (supabase) await addMessage(supabase, userMessageData);
        } catch (dbError) { console.error("Failed to save user message:", dbError); }

        if (text.trim()) {
             generateChatTitle(text.trim(), "", geminiApiKey).then(newTitle => {
                if (newTitle && newTitle !== "New Chat" && chatToUse.name === NEW_CHAT_NAME) {
                    handleUpdateChat(chatToUse.id, { name: newTitle });
                }
            }).catch(e => {});
        }

        // === EARLY EXIT FOR GROUP CHAT ===
        if (!shouldGenerate) {
            isSendingRef.current = false;
            setIsLoading(false);
            return { messages: [] };
        }

        const agentHistory = messages.map(m => m);
        const onStreamChunk = (chunk: string) => {
            if (abortController.signal.aborted) return;
            clearTimeout(safetyTimeout);
            if (!isMountedRef.current) return;
            if (activeChatIdRef.current !== chatToUse.id && activeChatIdRef.current !== null) return; 
            currentText += chunk;
            setMessages(prev => prev.map(m => m.id === tempId ? { ...m, text: currentText } : m));
        };

        const projectForAgent = chatToUse.projects ?? { ...DUMMY_AUTONOMOUS_PROJECT, user_id: user ? user.id : 'guest' };
        
        let modelToUse = 'gemini-2.5-flash';
        if (modelOverride) {
            modelToUse = modelOverride;
        } else if (!isGuest && profile) {
             modelToUse = (workspaceMode === 'cocreator' ? (profile.preferred_code_model || profile.preferred_chat_model) : profile.preferred_chat_model) || 'gemini-2.5-flash';
        }

        const agentResult = await runAgent({
            prompt: processedPrompt, 
            files: agentFiles, 
            apiKey: geminiApiKey || '', 
            model: modelToUse,
            project: projectForAgent, 
            chat: chatToUse, 
            user: user || { id: 'guest', email: 'guest', app_metadata: {}, user_metadata: {}, aud: 'guest', created_at: '' } as any, 
            profile: profile || null, 
            supabase: supabase as any, 
            history: agentHistory, 
            onStreamChunk, 
            onFileUpdate: onProjectFileUpdate,
            workspaceMode,
            thinkingMode: effectiveMode as any,
            signal: abortController.signal
        });
        
        if (abortController.signal.aborted) return { messages: [] };

        const { messages: agentMessages, updatedPlan } = agentResult;
        const savedAiMessages: Message[] = [];
        let finalAiText = "";

        for (const messageContent of agentMessages) {
            const finalContent = messageContent.text || currentText; 
            finalAiText += finalContent + " ";
            try {
                let savedAiMessage: Message;
                const aiData = { 
                    ...messageContent, 
                    text: finalContent, 
                    project_id: chatToUse.project_id,
                    model: isGuest ? 'Instant (Free)' : modelToUse 
                };

                if (isGuest) savedAiMessage = await localChatService.addMessage(aiData);
                else if (supabase) savedAiMessage = await addMessage(supabase, aiData);
                else throw new Error("No storage backend available");
                savedAiMessages.push(savedAiMessage);
            } catch (aiDbError) { console.error("Failed to save AI message:", aiDbError); }
        }
        
        if (supabase && (user || isGuest)) {
            const userId = user ? user.id : 'guest';
            extractAndSaveMemory(supabase, userId, text, finalAiText, chatToUse.project_id);
        }
        
        if (isMountedRef.current && (activeChatIdRef.current === chatToUse.id || activeChatIdRef.current === null)) {
            setMessages(prev => {
                const newMessages = [...prev];
                const tempMessageIndex = newMessages.findIndex(m => m.id === tempId);
                if (tempMessageIndex !== -1) {
                    if (savedAiMessages.length > 0) newMessages.splice(tempMessageIndex, 1, ...savedAiMessages);
                    else newMessages.splice(tempMessageIndex, 1);
                } else if (savedAiMessages.length > 0) {
                     newMessages.push(...savedAiMessages);
                }
                if (updatedPlan) return newMessages.map(m => m.id === updatedPlan.messageId ? { ...m, plan: updatedPlan.plan } : m);
                return newMessages;
            });
        }

        if (updatedPlan && !isGuest && supabase) await updateMessagePlan(supabase, updatedPlan.messageId, updatedPlan.plan);
        return agentResult;

      } catch (e: any) {
        if (abortController.signal.aborted || e.name === 'AbortError') return { messages: [] };
        const errorMessage = e?.message || "An unknown error occurred.";
        console.error("Message execution failed:", e);
        addToast(`Error: ${errorMessage}`, "error");
        
        if (isMountedRef.current && activeChatIdRef.current === chatToUse.id) {
            setMessages(prev => prev.map(m => m.id === tempId ? { ...m, text: `⚠️ I encountered an error: ${errorMessage}`, sender: 'ai' } : m));
        }
        return { messages: [] };
      } finally {
        clearTimeout(safetyTimeout);
        isSendingRef.current = false;
        if (isMountedRef.current) setIsLoading(false);
      }
    }, [activeChat, supabase, user, geminiApiKey, messages, addToast, profile, workspaceMode, handleUpdateChat, isGuest, activeUsersCount]);
    
    return {
        allChats, setAllChats, activeChat, setActiveChat, messages, setMessages,
        isLoading, isCreatingChat, setIsCreatingChat, activeProject,
        handleUpdateChat, handleSelectChat, handleDeleteChat, handleSendMessage, handleStopGeneration
    };
};
